{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e09c77ec-7562-4988-b03d-1ec5d8ca6b50",
   "metadata": {},
   "source": [
    "# Generar 'X' e 'y' para todos los experimentos\n",
    "<p>Como datos para las X se toma la media de los 17 canales de:</p>\n",
    "<ul>\n",
    "    <li>X_1: PSD de la banda delta (1~4Hz)</li>\n",
    "    <li>X_2: PSD de la banda theta (4~8Hz)</li>\n",
    "    <li>X_3: PSD de la banda alpha (8~14Hz)</li>\n",
    "    <li>X_4: PSD de la banda beta (14~31Hz)</li>\n",
    "    <li>X_5: PSD de la banda gamma (31~50 Hz)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072fe0e9-03e8-4705-ab92-0d9d129f12c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne.externals.pymatreader import read_mat\n",
    "\n",
    "from read import read_features\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac39ff71-b05b-4f8c-b0fd-5fc6b3462faf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = {\n",
    "    'leve': 0,\n",
    "    'moderada': 1,\n",
    "    'severa': 2\n",
    "}\n",
    "\n",
    "def parse_y(y, lim_leve=0.075, lim_moderada=0.15):\n",
    "    def classify(val):\n",
    "        if (val <= lim_leve):\n",
    "            return labels['leve']\n",
    "        if (val <= lim_moderada):\n",
    "            return labels['moderada']\n",
    "        return labels['severa']\n",
    "    \n",
    "    len_y = len(y)\n",
    "    classified = np.zeros(len_y, dtype=int)\n",
    "    \n",
    "    for i in range(len_y):\n",
    "        classified[i] = classify(y[i])\n",
    "        \n",
    "    return classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b3c7fc-b100-48c9-87f9-234676691435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Las que mejores graficas tienen\n",
    "# features_files = ['4_20151105_noon.mat', '4_20151107_noon.mat', '5_20141108_noon.mat','12_20150928_noon.mat','14_20151014_night.mat', '18_20150926_noon.mat', '21_20151016_noon.mat']\n",
    "\n",
    "# features_files = ['4_20151105_noon.mat', '5_20141108_noon.mat', '21_20151016_noon.mat']\n",
    "\n",
    "features_files = ['1_20151124_noon_2.csv', '2_20151106_noon.csv', '3_20151024_noon.csv','4_20151105_noon.csv', '4_20151107_noon.csv',\n",
    "            '5_20141108_noon.csv', '5_20151012_night.csv', '6_20151121_noon.csv','7_20151015_night.csv', '8_20151022_noon.csv', \n",
    "            '9_20151017_night.csv', '10_20151125_noon.csv', '11_20151024_night.csv', '12_20150928_noon.csv', '13_20150929_noon.csv',\n",
    "            '14_20151014_night.csv','15_20151126_night.csv', '16_20151128_night.csv', '17_20150925_noon.csv', '18_20150926_noon.csv',\n",
    "            '19_20151114_noon.csv', '20_20151129_night.csv', '21_20151016_noon.csv']\n",
    "\n",
    "# features_files = ['21_20151016_noon.csv']\n",
    "\n",
    "X_all = {} # psd\n",
    "X_all_eog = {} # psd + eog\n",
    "y_all = {} # datos perclos raw\n",
    "y_all_limits = {} # thresholds perclos para cada experimento\n",
    "y_all_class = {} # datos parseados a su clase\n",
    "\n",
    "for experiment in features_files:\n",
    "    \n",
    "    ''' EOG parpadeos por epoch'''\n",
    "    mat_data = read_mat(f'./SEED-VIG/Raw_Data/{experiment[:-4]}.mat')\n",
    "    \n",
    "    sfreq = mat_data['EOG']['eog_config']['current_sample_rate']\n",
    "    samples = mat_data['EOG']['eog_h']*1e-6 \n",
    "    samples = np.vstack((samples, mat_data['EOG']['eog_v']*1e-6))\n",
    "\n",
    "    ch_names = ['EOG_H', 'EOG_V']\n",
    "    ch_types = [\"eog\"]*len(ch_names)\n",
    "\n",
    "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "\n",
    "    info.set_montage('standard_1020')\n",
    "    \n",
    "    raw = mne.io.RawArray(samples, info, verbose=False)\n",
    "    \n",
    "    # Busqueda del treshold para el parpadeo\n",
    "    # En los 5 primeros segundos del experimento, buscamos el percentil 2.5 y calculamos su valor absoluto como threshold para detectar parpadeos\n",
    "    threshold = abs(np.percentile(raw.get_data()[1][:5*1000], 2.5))\n",
    "    \n",
    "    blinks = mne.preprocessing.find_eog_events(raw, filter_length='10s', thresh=threshold, verbose=False)\n",
    "    blinks = blinks.T[0]\n",
    "    \n",
    "    n_samples = 885\n",
    "    dur_sample = 8 # segs\n",
    "    len_sample = 8*125\n",
    "    \n",
    "    blinks_per_sample = []\n",
    "    for i in range(n_samples):\n",
    "        blinks_per_sample.append([])\n",
    "        \n",
    "    for val in blinks:\n",
    "        blinks_per_sample[val//len_sample].append(val)\n",
    "    \n",
    "    n_blinks_per_sample = [0]*n_samples\n",
    "        \n",
    "    for i in range(885):\n",
    "        n_blinks_per_sample[i] = len(blinks_per_sample[i])\n",
    "        \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    n_blinks_per_sample = np.array(n_blinks_per_sample)\n",
    "    n_blinks_per_sample = scaler.fit_transform(n_blinks_per_sample.reshape(-1,1))\n",
    "    \n",
    "    \n",
    "    ''' PSD '''\n",
    "    mat_data = read_mat(f'./SEED-VIG/EEG_Feature_5Bands/{experiment[:-4]}.mat')\n",
    "    perclos_data = read_mat(f'./SEED-VIG/perclos_labels/{experiment[:-4]}.mat')\n",
    "    y = np.array(perclos_data['perclos'])\n",
    "\n",
    "    n_channels = 17\n",
    "    psd_data = mat_data['psd_movingAve']\n",
    "    perclos = []\n",
    "    psd_delta = []\n",
    "    psd_theta = []\n",
    "    psd_alpha = []\n",
    "    psd_beta = []\n",
    "    psd_gamma = []\n",
    "    start = 0\n",
    "    end = 885\n",
    "    for t in range(start, end):\n",
    "        vals= np.zeros(5)\n",
    "\n",
    "        for i in range(n_channels):\n",
    "            vals[0] += psd_data[i][t][0]\n",
    "            vals[1] += psd_data[i][t][1]\n",
    "            vals[2] += psd_data[i][t][2]\n",
    "            vals[3] += psd_data[i][t][3]\n",
    "            vals[4] += psd_data[i][t][4]\n",
    "        vals /= 17\n",
    "\n",
    "        perclos.append(y[t])\n",
    "        psd_delta.append(vals[0])\n",
    "        psd_theta.append(vals[1])\n",
    "        psd_alpha.append(vals[2])\n",
    "        psd_beta.append(vals[3])\n",
    "        psd_gamma.append(vals[4])\n",
    "\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    psd_delta = np.array(psd_delta)\n",
    "    psd_delta = scaler.fit_transform(psd_delta.reshape(-1,1))\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    psd_theta = np.array(psd_theta)\n",
    "    psd_theta = scaler.fit_transform(psd_theta.reshape(-1,1))\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    psd_alpha = np.array(psd_alpha)\n",
    "    psd_alpha = scaler.fit_transform(psd_alpha.reshape(-1,1))\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    psd_beta = np.array(psd_beta)\n",
    "    psd_beta = scaler.fit_transform(psd_beta.reshape(-1,1))\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    psd_gamma = np.array(psd_gamma)\n",
    "    psd_gamma = scaler.fit_transform(psd_gamma.reshape(-1,1))\n",
    "\n",
    "    X = psd_delta\n",
    "    X = np.hstack((X, psd_theta))\n",
    "    X = np.hstack((X, psd_alpha))\n",
    "    X = np.hstack((X, psd_beta))\n",
    "    ''' DESCOMENTAR PARA USAR PSD DE GAMMA '''\n",
    "    X = np.hstack((X, psd_gamma))\n",
    "    \n",
    "    X_all[f'{experiment[:-4]}'] = X # guardamos los psd\n",
    "    \n",
    "    X = np.hstack((X, n_blinks_per_sample))\n",
    "    \n",
    "    X_all_eog[f'{experiment[:-4]}'] = X # guardamos psd + eog\n",
    "    \n",
    "    ''' LABELS '''\n",
    "    y_all[f'{experiment[:-4]}'] = y # guardamos perclos raw\n",
    "    \n",
    "    range_values = (np.max(y)-np.min(y))/100\n",
    "    lim_leve = np.min(y)+range_values*12.5\n",
    "    lim_moderada = np.min(y)+range_values*30\n",
    "    y_all_limits[f'{experiment[:-4]}'] = [lim_leve, lim_moderada]\n",
    "    \n",
    "    y_all_class[f'{experiment[:-4]}'] = parse_y(y, lim_leve, lim_moderada) # guardamos ya clasificada\n",
    "    \n",
    "print(f'Generados los diccionarios X_all e y_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdee812e-c7b2-482e-97a1-38a02a22325c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(X_all_eog['21_20151016_noon'].shape)\n",
    "\n",
    "for key in X_all:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb90087-75f0-4e5a-9576-fd364bb18dc9",
   "metadata": {},
   "source": [
    "# Busqueda de hyperparametros y muestra de los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a19bf8-e3d5-4fa7-9bb5-8647069a7f69",
   "metadata": {},
   "source": [
    "## Funciones para la busqueda y el plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5eb445-0f16-4d3f-86b4-b40623b0f1ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "from scipy.stats import uniform, randint, loguniform, gamma\n",
    "\n",
    "def find_and_test_best_model_class(X, y, model, space, cv=10, n_iter=100, scoring=None, conf_mat=True):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    search = RandomizedSearchCV(model, space, n_iter=n_iter, scoring=scoring, n_jobs=-1, cv=cv, random_state=42)\n",
    "    result = search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Best Model:\")\n",
    "    print(f\"\\tScore: {result.best_score_:.4f}\")\n",
    "    print(f\"\\tHyperparameters: {result.best_params_}\")\n",
    "    \n",
    "    print('\\nResults with X_test:')\n",
    "    best_model = result.best_estimator_\n",
    "    final_predictions = best_model.predict(X_test)\n",
    "    \n",
    "    #TODO sklearn.metrics.classification_report ofrece los siguientes parametros y alguna cosilla mas, puede ser interesante ???\n",
    "    acc = accuracy_score(y_test, final_predictions)\n",
    "    pre = precision_score(y_test, final_predictions, average='macro', zero_division=1)\n",
    "    rec = recall_score(y_test, final_predictions, average='macro', zero_division=1)\n",
    "    f1 = f1_score(y_test, final_predictions, average='macro', zero_division=1)\n",
    "    print(f\"\\tAccuracy: {acc*100:.2f}%\")\n",
    "    print(f\"\\tPrecision: {pre:.4f}\")\n",
    "    print(f\"\\tRecall: {rec:.4f}\")\n",
    "    print(f\"\\tf1: {f1:.4f}\")\n",
    "    \n",
    "    ''' PARA MOSTRAR LA MATRIZ DE CONFUSION HAY QUE PASAR EL PARAMETRO conf_mat=True '''\n",
    "    if (conf_mat):\n",
    "        print(f'Matriz de confusiÃ³n para X completo')\n",
    "        try:\n",
    "            plt.rcParams.update({'font.size': 16, 'font.weight': 'bold'})\n",
    "            fig, ax = plt.subplots(figsize=(10, 5))\n",
    "            plot_confusion_matrix(best_model, X, y, ax=ax, display_labels=['leve', 'moderara', 'severa'], colorbar=False)\n",
    "            size_ticks = 16; plt.xticks(fontsize=size_ticks, fontweight ='normal'); plt.yticks(fontsize=size_ticks, fontweight ='normal');\n",
    "            size_label = 20; plt.xlabel('Predicted Label', fontweight ='bold', labelpad = 10,fontsize = size_label); plt.ylabel('True Label', fontweight ='bold', labelpad = 10,fontsize = size_label);\n",
    "            plt.savefig(\"E:/UNIVERSIDAD/TFG/TRABAJO/Images-Test/NOMBRE.pdf\", bbox_inches='tight')\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return best_model, acc, pre, rec, f1\n",
    "\n",
    "def map_2_colors(y, labels):\n",
    "    label_2_color = {\n",
    "        0: 'green',\n",
    "        1: 'orange',\n",
    "        2: 'red'\n",
    "    }\n",
    "    \n",
    "    cmap = []\n",
    "    for i in range(len(y)):\n",
    "        cmap.append(label_2_color[y[i]])\n",
    "    return cmap\n",
    "\n",
    "def plot_results_class(X, y, model, lim_leve_moderada, lim_moderada_severa):\n",
    "    plt.rcParams.update({'font.size': 30, 'font.weight': 'normal'})\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.axhspan(0, lim_leve_moderada, facecolor='green', alpha=0.2, label=\"Somnolencia leve\")\n",
    "    plt.axhspan(lim_leve_moderada, lim_moderada_severa, facecolor='orange', alpha=0.2, label=\"Somnolencia moderada\")\n",
    "    plt.axhspan(lim_moderada_severa, 1, facecolor='red', alpha=0.2, label=\"Somnolencia severa\")\n",
    "#     plt.plot(y, c='k', alpha=0.6)\n",
    "    colors = map_2_colors(model.predict(X), labels)\n",
    "    plt.scatter(range(len(y)), y, c=colors)\n",
    "#     plt.legend(bbox_to_anchor=(1, 1), loc='upper left')\n",
    "    size_label = 26; plt.xlabel('Epoch', fontweight ='bold', labelpad = 10,fontsize = size_label); plt.ylabel('PERCLOS', fontweight ='bold', labelpad = 10,fontsize = size_label);\n",
    "    size_ticks = 24; plt.xticks(fontsize=size_ticks); plt.yticks(fontsize=size_ticks);\n",
    "    plt.savefig(\"E:/UNIVERSIDAD/TFG/TRABAJO/Images-Test/NOMBRE2.pdf\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b017d9ab-60e2-479a-9c3e-7a8ad62347db",
   "metadata": {},
   "source": [
    "# SVM classifier (No va tan bien)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bada36-65c2-4187-a194-4fdfa63f7432",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b9003a-e615-4623-ba2c-a2623a9c6575",
   "metadata": {},
   "source": [
    "### Mean, STD, var, p05, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a348db05-a218-4647-832b-b824e6e0034f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'acc': [],\n",
    "    'pre': [],\n",
    "    'rec': [],\n",
    "    \"f1\": []\n",
    "}\n",
    "\n",
    "for file in features_files:\n",
    "    \n",
    "    X, y = read_features(f'./features/{file[:-4]}.csv')\n",
    "    #X, y = read_features(file, features=[0, 1])\n",
    "    key = file[:-4]\n",
    "    y = y_all[key]\n",
    "    y_class = y_all_class[key]\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_minmax = scaler.fit_transform(X)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_standar = scaler.fit_transform(X)\n",
    "\n",
    "    key = file[:-4]\n",
    "    print(f\"Experiment: {key}\")\n",
    "    model = svm.SVC(random_state=42)\n",
    "\n",
    "    cv = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['C'] = uniform(1, 20)\n",
    "    space['kernel'] = ['linear', 'rbf']\n",
    "    space['gamma'] = ['scale', 'auto']\n",
    "    space['shrinking'] = [True, False]\n",
    "    space['probability'] = [True, False]\n",
    "    space['decision_function_shape'] = ['ovo', 'ovr']\n",
    "\n",
    "    best_model, acc, pre, rec, f1= find_and_test_best_model_class(X_minmax, y_class, model, space, cv, 35)\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['acc'].append(acc)\n",
    "    csv_dict['pre'].append(pre)\n",
    "    csv_dict['rec'].append(rec)\n",
    "    csv_dict['f1'].append(f1)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_class(X_minmax, y, best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_cla/SVM_c-EEG.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75f41a2-2c07-41fb-9781-6046fb8be40f",
   "metadata": {},
   "source": [
    "### PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bb58e0-d487-4a1f-b1b4-f0e5724391b0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'acc': [],\n",
    "    'pre': [],\n",
    "    'rec': [],\n",
    "    \"f1\": []\n",
    "}\n",
    "\n",
    "for key in X_all:\n",
    "    print(f\"Experiment: {key}\")\n",
    "    model = svm.SVC(random_state=42)\n",
    "\n",
    "    cv = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['C'] = uniform(1, 20)\n",
    "    space['kernel'] = ['linear', 'rbf']\n",
    "    space['gamma'] = ['scale', 'auto']\n",
    "    space['shrinking'] = [True, False]\n",
    "    space['probability'] = [True, False]\n",
    "    space['decision_function_shape'] = ['ovo', 'ovr']\n",
    "\n",
    "    best_model, acc, pre, rec, f1= find_and_test_best_model_class(X_all[key], y_all_class[key], model, space, cv, 100)\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['acc'].append(acc)\n",
    "    csv_dict['pre'].append(pre)\n",
    "    csv_dict['rec'].append(rec)\n",
    "    csv_dict['f1'].append(f1)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_class(X_all[key], y_all[key], best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_cla/SVM_c-PSD.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afb0d96-7d31-48e5-bcbe-5fe854b4b85a",
   "metadata": {},
   "source": [
    "### PSD + EOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240b5982-e8f2-4c24-94c2-8085b0dca93d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'acc': [],\n",
    "    'pre': [],\n",
    "    'rec': [],\n",
    "    \"f1\": []\n",
    "}\n",
    "\n",
    "for key in X_all:\n",
    "    print(f\"Experiment: {key}\")\n",
    "    model = svm.SVC(random_state=42)\n",
    "\n",
    "    cv = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['C'] = uniform(1, 20)\n",
    "    space['kernel'] = ['linear', 'rbf']\n",
    "    space['gamma'] = ['scale', 'auto']\n",
    "    space['shrinking'] = [True, False]\n",
    "    space['probability'] = [True, False]\n",
    "    space['decision_function_shape'] = ['ovo', 'ovr']\n",
    "\n",
    "    best_model, acc, pre, rec, f1= find_and_test_best_model_class(X_all_eog[key], y_all_class[key], model, space, cv, 100)\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['acc'].append(acc)\n",
    "    csv_dict['pre'].append(pre)\n",
    "    csv_dict['rec'].append(rec)\n",
    "    csv_dict['f1'].append(f1)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_class(X_all_eog[key], y_all[key], best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_cla/SVM_c-PSD+EOG.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0a4e08-44be-429f-9420-13eb1b12ac7c",
   "metadata": {},
   "source": [
    "# KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da7dd69-32ba-4e8b-9a64-3bba02606322",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d14c2d-9bba-47bd-98dc-8102cb00126b",
   "metadata": {},
   "source": [
    "### Mean, STD, var, p05, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ebf4a6-a268-4778-a3d3-7a3279595736",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'acc': [],\n",
    "    'pre': [],\n",
    "    'rec': [],\n",
    "    \"f1\": []\n",
    "}\n",
    "\n",
    "for file in features_files:\n",
    "    \n",
    "    X, y = read_features(f'./features/{file[:-4]}.csv')\n",
    "    #X, y = read_features(file, features=[0, 1])\n",
    "    key = file[:-4]\n",
    "    y = y_all[key]\n",
    "    y_class = y_all_class[key]\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_minmax = scaler.fit_transform(X)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_standar = scaler.fit_transform(X)\n",
    "\n",
    "    key = file[:-4]\n",
    "    print(f\"Experiment: {key}\")\n",
    "    model = KNeighborsClassifier()\n",
    "\n",
    "    cv = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['n_neighbors'] = randint(3, 21)\n",
    "    space['weights'] = ['uniform', 'distance']\n",
    "    space['algorithm'] = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    space['leaf_size'] = randint(15,50)\n",
    "    space['p'] = [1, 2]\n",
    "\n",
    "    best_model, acc, pre, rec, f1= find_and_test_best_model_class(X_minmax, y_class, model, space, cv, 100)\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['acc'].append(acc)\n",
    "    csv_dict['pre'].append(pre)\n",
    "    csv_dict['rec'].append(rec)\n",
    "    csv_dict['f1'].append(f1)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_class(X_minmax, y, best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_cla/KNN-EEG.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656f7c6b-01b0-4cfc-b8e6-b8d56276a4fc",
   "metadata": {},
   "source": [
    "### PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6493ea-f65d-456c-8d72-62d6b742ae87",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'acc': [],\n",
    "    'pre': [],\n",
    "    'rec': [],\n",
    "    \"f1\": []\n",
    "}\n",
    "\n",
    "for key in X_all:\n",
    "    print(f\"Experiment: {key}\")\n",
    "    model = KNeighborsClassifier()\n",
    "    cv = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['n_neighbors'] = randint(3, 21)\n",
    "    space['weights'] = ['uniform', 'distance']\n",
    "    space['algorithm'] = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    space['leaf_size'] = randint(15,50)\n",
    "    space['p'] = [1, 2]\n",
    "\n",
    "    best_model, acc, pre, rec, f1= find_and_test_best_model_class(X_all[key], y_all_class[key], model, space, cv, 100)\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['acc'].append(acc)\n",
    "    csv_dict['pre'].append(pre)\n",
    "    csv_dict['rec'].append(rec)\n",
    "    csv_dict['f1'].append(f1)\n",
    "    \n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_class(X_all[key], y_all[key], best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_cla/KNN-PSD.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74843658-a4b7-4c63-9fb4-0eaa920ac747",
   "metadata": {},
   "source": [
    "### PSD + EOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ada92d-41b6-411f-a477-797a98e0e077",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'acc': [],\n",
    "    'pre': [],\n",
    "    'rec': [],\n",
    "    \"f1\": []\n",
    "}\n",
    "\n",
    "for key in X_all:\n",
    "    print(f\"Experiment: {key}\")\n",
    "    model = KNeighborsClassifier()\n",
    "    cv = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['n_neighbors'] = randint(3, 21)\n",
    "    space['weights'] = ['uniform', 'distance']\n",
    "    space['algorithm'] = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "    space['leaf_size'] = randint(15,50)\n",
    "    space['p'] = [1, 2]\n",
    "\n",
    "    best_model, acc, pre, rec, f1= find_and_test_best_model_class(X_all_eog[key], y_all_class[key], model, space, cv, 100)\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['acc'].append(acc)\n",
    "    csv_dict['pre'].append(pre)\n",
    "    csv_dict['rec'].append(rec)\n",
    "    csv_dict['f1'].append(f1)\n",
    "    \n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_class(X_all_eog[key], y_all[key], best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_cla/KNN-PSD+EOG.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c7243a-ecd5-4e75-8063-28ceb90c2a03",
   "metadata": {},
   "source": [
    "# Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4149b82c-0877-498e-ac47-b166967b4164",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e2ffdf-1fc3-44c6-9f35-4c857c92f89d",
   "metadata": {},
   "source": [
    "### Mean, STD, var, p05, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30739d2b-93b9-450f-b077-3e92c3868378",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'acc': [],\n",
    "    'pre': [],\n",
    "    'rec': [],\n",
    "    \"f1\": []\n",
    "}\n",
    "\n",
    "for file in features_files:\n",
    "    \n",
    "    X, y = read_features(f'./features/{file[:-4]}.csv')\n",
    "    #X, y = read_features(file, features=[0, 1])\n",
    "    key = file[:-4]\n",
    "    y = y_all[key]\n",
    "    y_class = y_all_class[key]\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_minmax = scaler.fit_transform(X)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_standar = scaler.fit_transform(X)\n",
    "\n",
    "    key = file[:-4]\n",
    "    print(f\"Experiment: {key}\")\n",
    "    model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    cv = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['criterion'] = [\"gini\", \"entropy\"]\n",
    "    space['splitter'] = [\"best\", \"random\"]\n",
    "    space['max_depth'] = randint(5, 100)\n",
    "    space['min_samples_split'] = randint(2, 10)\n",
    "    #space['min_samples_leaf'] = randint(1, 10)\n",
    "    space['max_features'] = [\"auto\", \"sqrt\", \"log2\"]\n",
    "    #space['ccp_alpha'] = uniform(0, 5) # empeora el ponerlo, el mejor valor es 0.0\n",
    "\n",
    "    best_model, acc, pre, rec, f1= find_and_test_best_model_class(X_minmax, y_class, model, space, cv, 150)\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['acc'].append(acc)\n",
    "    csv_dict['pre'].append(pre)\n",
    "    csv_dict['rec'].append(rec)\n",
    "    csv_dict['f1'].append(f1)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_class(X_minmax, y, best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_cla/DT-EEG.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14e7e1f-245a-4e69-9e14-3f07e0298868",
   "metadata": {},
   "source": [
    "### PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44edd0d1-c8ea-4e67-a057-567dae8d58b8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'acc': [],\n",
    "    'pre': [],\n",
    "    'rec': [],\n",
    "    \"f1\": []\n",
    "}\n",
    "\n",
    "for key in X_all:\n",
    "    print(f\"Experiment: {key}\")\n",
    "\n",
    "    model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    cv = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['criterion'] = [\"gini\", \"entropy\"]\n",
    "    space['splitter'] = [\"best\", \"random\"]\n",
    "    space['max_depth'] = randint(5, 100)\n",
    "    space['min_samples_split'] = randint(2, 10)\n",
    "    #space['min_samples_leaf'] = randint(1, 10)\n",
    "    space['max_features'] = [\"auto\", \"sqrt\", \"log2\"]\n",
    "    #space['ccp_alpha'] = uniform(0, 5) # empeora el ponerlo, el mejor valor es 0.0\n",
    "\n",
    "    best_model, acc, pre, rec, f1= find_and_test_best_model_class(X_all[key], y_all_class[key], model, space, cv, 150)\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['acc'].append(acc)\n",
    "    csv_dict['pre'].append(pre)\n",
    "    csv_dict['rec'].append(rec)\n",
    "    csv_dict['f1'].append(f1)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_class(X_all[key], y_all[key], best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_cla/DT-PSD.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d86bd78-0ac6-4536-ae58-1a9ac3730c26",
   "metadata": {},
   "source": [
    "### PSD + EOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c34eaa-6592-43cb-ab7e-155e50c74c44",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'acc': [],\n",
    "    'pre': [],\n",
    "    'rec': [],\n",
    "    \"f1\": []\n",
    "}\n",
    "\n",
    "for key in X_all:\n",
    "    print(f\"Experiment: {key}\")\n",
    "\n",
    "    model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    cv = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['criterion'] = [\"gini\", \"entropy\"]\n",
    "    space['splitter'] = [\"best\", \"random\"]\n",
    "    space['max_depth'] = randint(5, 100)\n",
    "    space['min_samples_split'] = randint(2, 10)\n",
    "    #space['min_samples_leaf'] = randint(1, 10)\n",
    "    space['max_features'] = [\"auto\", \"sqrt\", \"log2\"]\n",
    "    #space['ccp_alpha'] = uniform(0, 5) # empeora el ponerlo, el mejor valor es 0.0\n",
    "\n",
    "    best_model, acc, pre, rec, f1= find_and_test_best_model_class(X_all_eog[key], y_all_class[key], model, space, cv, 150)\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['acc'].append(acc)\n",
    "    csv_dict['pre'].append(pre)\n",
    "    csv_dict['rec'].append(rec)\n",
    "    csv_dict['f1'].append(f1)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_class(X_all_eog[key], y_all[key], best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_cla/DT-PSD+EOG.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d26b42-aa45-4850-afce-1fc6ed576b89",
   "metadata": {},
   "source": [
    "# Gaussian Process classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2786b5-c3b6-4e55-938c-96121194eb72",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ea615a-6845-4780-8e4a-eab7b1c80187",
   "metadata": {},
   "source": [
    "### Mean, STD, var, p05, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853a6928-ded3-49bc-a822-8c0114cfd446",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'acc': [],\n",
    "    'pre': [],\n",
    "    'rec': [],\n",
    "    \"f1\": []\n",
    "}\n",
    "\n",
    "for file in features_files:\n",
    "    \n",
    "    X, y = read_features(f'./features/{file[:-4]}.csv')\n",
    "    #X, y = read_features(f'./features/{file[:-4]}.csv', features=[0, 1])\n",
    "    key = file[:-4]\n",
    "    y = y_all[key]\n",
    "    y_class = y_all_class[key]\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_minmax = scaler.fit_transform(X)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_standar = scaler.fit_transform(X)\n",
    "\n",
    "    key = file[:-4]\n",
    "    print(f\"Experiment: {key}\")\n",
    "    model = GaussianProcessClassifier(random_state=42)\n",
    "\n",
    "    cv = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['optimizer'] = [\"fmin_l_bfgs_b\"]\n",
    "    space['n_restarts_optimizer'] = randint(0, 5)\n",
    "    space['max_iter_predict'] = randint(75, 200)\n",
    "    space['warm_start'] = [True, False]\n",
    "    space['multi_class'] = ['one_vs_rest', 'one_vs_one']\n",
    "\n",
    "    best_model, acc, pre, rec, f1= find_and_test_best_model_class(X_minmax, y_class, model, space, cv, 20)\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['acc'].append(acc)\n",
    "    csv_dict['pre'].append(pre)\n",
    "    csv_dict['rec'].append(rec)\n",
    "    csv_dict['f1'].append(f1)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_class(X_minmax, y, best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_cla/GP-EEG.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469c534b-3ee4-4123-a4d5-7c0485bcdc4a",
   "metadata": {},
   "source": [
    "### PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05d3e0a-09fc-42cf-a4de-3c9bb7760c47",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'acc': [],\n",
    "    'pre': [],\n",
    "    'rec': [],\n",
    "    \"f1\": []\n",
    "}\n",
    "\n",
    "for key in X_all:\n",
    "    print(f\"Experiment: {key}\")\n",
    "\n",
    "    model = GaussianProcessClassifier(random_state=42)\n",
    "\n",
    "    cv = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['optimizer'] = [\"fmin_l_bfgs_b\"]\n",
    "    space['n_restarts_optimizer'] = randint(0, 5)\n",
    "    space['max_iter_predict'] = randint(75, 200)\n",
    "    space['warm_start'] = [True, False]\n",
    "    space['multi_class'] = ['one_vs_rest', 'one_vs_one']\n",
    "\n",
    "    best_model, acc, pre, rec, f1= find_and_test_best_model_class(X_all[key], y_all_class[key], model, space, cv, 10)\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['acc'].append(acc)\n",
    "    csv_dict['pre'].append(pre)\n",
    "    csv_dict['rec'].append(rec)\n",
    "    csv_dict['f1'].append(f1)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_class(X_all[key], y_all[key], best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_cla/GP-PSD.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa28aff-86ff-45cf-a2b5-577d346f7419",
   "metadata": {},
   "source": [
    "### PSD + EOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5833d5-0888-4274-9e3e-d7d50d810e7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'acc': [],\n",
    "    'pre': [],\n",
    "    'rec': [],\n",
    "    \"f1\": []\n",
    "}\n",
    "\n",
    "for key in X_all:\n",
    "    print(f\"Experiment: {key}\")\n",
    "\n",
    "    model = GaussianProcessClassifier(random_state=42)\n",
    "\n",
    "    cv = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['optimizer'] = [\"fmin_l_bfgs_b\"]\n",
    "    space['n_restarts_optimizer'] = randint(0, 5)\n",
    "    space['max_iter_predict'] = randint(75, 200)\n",
    "    space['warm_start'] = [True, False]\n",
    "    space['multi_class'] = ['one_vs_rest', 'one_vs_one']\n",
    "\n",
    "    best_model, acc, pre, rec, f1= find_and_test_best_model_class(X_all_eog[key], y_all_class[key], model, space, cv, 10)\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['acc'].append(acc)\n",
    "    csv_dict['pre'].append(pre)\n",
    "    csv_dict['rec'].append(rec)\n",
    "    csv_dict['f1'].append(f1)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_class(X_all_eog[key], y_all[key], best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_cla/GP-PSD+EOG.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57552c1-56b4-4735-9ea9-670b5c63d45d",
   "metadata": {},
   "source": [
    "# Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9281e9a-ff85-4a69-8096-03f90ecc1239",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32900f72-68d7-4e72-811e-526a9e5e69be",
   "metadata": {},
   "source": [
    "### Mean, STD, var, p05, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ba7c34-047a-4fc8-9178-882be9945770",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'acc': [],\n",
    "    'pre': [],\n",
    "    'rec': [],\n",
    "    \"f1\": []\n",
    "}\n",
    "\n",
    "for file in features_files:\n",
    "    \n",
    "    X, y = read_features(f'./features/{file[:-4]}.csv')\n",
    "#     X, y = read_features(f'./features/{file[:-4]}.csv', features=[0, 1])\n",
    "    key = file[:-4]\n",
    "    y = y_all[key]\n",
    "    y_class = y_all_class[key]\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_minmax = scaler.fit_transform(X)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_standar = scaler.fit_transform(X)\n",
    "\n",
    "    key = file[:-4]\n",
    "    print(f\"Experiment: {key}\")\n",
    "    model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "    cv = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['n_estimators'] = randint(75, 200)\n",
    "    space['criterion'] = [\"gini\", \"entropy\"]\n",
    "    space['max_depth'] = randint(75, 150)\n",
    "    space['min_samples_split'] = randint(2, 10)\n",
    "    space['min_samples_leaf'] = randint(1, 10)\n",
    "    # space['min_weight_fraction_leaf'] = uniform(0, 0.5)\n",
    "    space['max_features'] = [\"auto\", \"sqrt\", \"log2\"]\n",
    "    #space['max_leaf_nodes'] = randint(1, 300)\n",
    "    # space['min_impurity_decrease'] = uniform(0, 5)\n",
    "    #space['bootstrap'] = [True, False]\n",
    "    # space['oob_score'] = [True, False]\n",
    "    space['warm_start'] = [True, False]\n",
    "    # space['class_weight'] = ['balanced', 'balanced_subsample']\n",
    "    #space['ccp_alpha'] = uniform(0, 5)\n",
    "    #space['max_samples'] = uniform(0, 1)\n",
    "\n",
    "    best_model, acc, pre, rec, f1= find_and_test_best_model_class(X_minmax, y_class, model, space, cv, 20)\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['acc'].append(acc)\n",
    "    csv_dict['pre'].append(pre)\n",
    "    csv_dict['rec'].append(rec)\n",
    "    csv_dict['f1'].append(f1)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_class(X_minmax, y, best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_cla/RF-EEG.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a204359-7b2f-4e31-bb73-924c22473127",
   "metadata": {},
   "source": [
    "### PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e764dfc3-4ad8-4d53-93a3-7ebba5f8f951",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['5_20141108_noon']:\n",
    "    print(f\"Experiment: {key}\")\n",
    "\n",
    "    model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "    cv = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['n_estimators'] = randint(75, 200)\n",
    "    space['criterion'] = [\"gini\", \"entropy\"]\n",
    "    space['max_depth'] = randint(75, 150)\n",
    "    space['min_samples_split'] = randint(2, 10)\n",
    "    space['min_samples_leaf'] = randint(1, 10)\n",
    "    # space['min_weight_fraction_leaf'] = uniform(0, 0.5)\n",
    "    space['max_features'] = [\"auto\", \"sqrt\", \"log2\"]\n",
    "    #space['max_leaf_nodes'] = randint(1, 300)\n",
    "    # space['min_impurity_decrease'] = uniform(0, 5)\n",
    "    #space['bootstrap'] = [True, False]\n",
    "    # space['oob_score'] = [True, False]\n",
    "    space['warm_start'] = [True, False]\n",
    "    # space['class_weight'] = ['balanced', 'balanced_subsample']\n",
    "    #space['ccp_alpha'] = uniform(0, 5)\n",
    "    #space['max_samples'] = uniform(0, 1)\n",
    "\n",
    "    best_model, acc, pre, rec, f1= find_and_test_best_model_class(X_all[key], y_all_class[key], model, space, cv, 20, conf_mat=True)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_class(X_all[key], y_all[key], best_model, lim_leve_moderada, lim_moderada_severa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d27e859-c323-4ab8-a40c-b5b377d9a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 12, 'font.weight': 'bold'})\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "plot_confusion_matrix(best_model, X_all[key], y_all_class[key], ax=ax, display_labels=['leve', 'moderara', 'severa'], colorbar=False)\n",
    "size_ticks = 12; plt.xticks(fontsize=size_ticks, fontweight ='normal'); plt.yticks(fontsize=size_ticks, fontweight ='normal');\n",
    "size_label = 14; plt.xlabel('Predicted Label', fontweight ='bold', labelpad = 10,fontsize = size_label); plt.ylabel('True Label', fontweight ='bold', labelpad = 10,fontsize = size_label);\n",
    "plt.savefig(\"E:/UNIVERSIDAD/TFG/TRABAJO/Images-Test/perclos-class-confmat.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd78c0a4-c60e-4717-855b-57c5a758636b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'acc': [],\n",
    "    'pre': [],\n",
    "    'rec': [],\n",
    "    \"f1\": []\n",
    "}\n",
    "\n",
    "for key in X_all:\n",
    "    print(f\"Experiment: {key}\")\n",
    "\n",
    "    model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "    cv = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['n_estimators'] = randint(75, 200)\n",
    "    space['criterion'] = [\"gini\", \"entropy\"]\n",
    "    space['max_depth'] = randint(75, 150)\n",
    "    space['min_samples_split'] = randint(2, 10)\n",
    "    space['min_samples_leaf'] = randint(1, 10)\n",
    "    # space['min_weight_fraction_leaf'] = uniform(0, 0.5)\n",
    "    space['max_features'] = [\"auto\", \"sqrt\", \"log2\"]\n",
    "    #space['max_leaf_nodes'] = randint(1, 300)\n",
    "    # space['min_impurity_decrease'] = uniform(0, 5)\n",
    "    #space['bootstrap'] = [True, False]\n",
    "    # space['oob_score'] = [True, False]\n",
    "    space['warm_start'] = [True, False]\n",
    "    # space['class_weight'] = ['balanced', 'balanced_subsample']\n",
    "    #space['ccp_alpha'] = uniform(0, 5)\n",
    "    #space['max_samples'] = uniform(0, 1)\n",
    "\n",
    "    best_model, acc, pre, rec, f1= find_and_test_best_model_class(X_all[key], y_all_class[key], model, space, cv, 20, conf_mat=False)\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['acc'].append(acc)\n",
    "    csv_dict['pre'].append(pre)\n",
    "    csv_dict['rec'].append(rec)\n",
    "    csv_dict['f1'].append(f1)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_class(X_all[key], y_all[key], best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_cla/RF-PSD.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1d581d-c194-4dc3-90ce-28725d2bab32",
   "metadata": {},
   "source": [
    "### PSD + EOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660afca3-7855-4f63-b8e8-20f80e7aa1dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'acc': [],\n",
    "    'pre': [],\n",
    "    'rec': [],\n",
    "    \"f1\": []\n",
    "}\n",
    "\n",
    "for key in X_all:\n",
    "    print(f\"Experiment: {key}\")\n",
    "\n",
    "    model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "    cv = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['n_estimators'] = randint(75, 200)\n",
    "    space['criterion'] = [\"gini\", \"entropy\"]\n",
    "    space['max_depth'] = randint(75, 150)\n",
    "    space['min_samples_split'] = randint(2, 10)\n",
    "    space['min_samples_leaf'] = randint(1, 10)\n",
    "    # space['min_weight_fraction_leaf'] = uniform(0, 0.5)\n",
    "    space['max_features'] = [\"auto\", \"sqrt\", \"log2\"]\n",
    "    #space['max_leaf_nodes'] = randint(1, 300)\n",
    "    # space['min_impurity_decrease'] = uniform(0, 5)\n",
    "    #space['bootstrap'] = [True, False]\n",
    "    # space['oob_score'] = [True, False]\n",
    "    space['warm_start'] = [True, False]\n",
    "    # space['class_weight'] = ['balanced', 'balanced_subsample']\n",
    "    #space['ccp_alpha'] = uniform(0, 5)\n",
    "    #space['max_samples'] = uniform(0, 1)\n",
    "\n",
    "    best_model, acc, pre, rec, f1= find_and_test_best_model_class(X_all_eog[key], y_all_class[key], model, space, cv, 20)\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['acc'].append(acc)\n",
    "    csv_dict['pre'].append(pre)\n",
    "    csv_dict['rec'].append(rec)\n",
    "    csv_dict['f1'].append(f1)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_class(X_all_eog[key], y_all[key], best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_cla/RF-PSD+EOG.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f62009b-3506-4656-b710-6b095e8ba681",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
