{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e09c77ec-7562-4988-b03d-1ec5d8ca6b50",
   "metadata": {},
   "source": [
    "# Generar 'X' e 'y' para todos los experimentos\n",
    "<p>Como datos para las X se toma la media de los 17 canales de:</p>\n",
    "<ul>\n",
    "    <li>X_1: PSD de la banda delta (1~4Hz)</li>\n",
    "    <li>X_2: PSD de la banda theta (4~8Hz)</li>\n",
    "    <li>X_3: PSD de la banda alpha (8~14Hz)</li>\n",
    "    <li>X_4: PSD de la banda beta (14~31Hz)</li>\n",
    "    <li>X_5: PSD de la banda gamma (31~50 Hz)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952019d1-94da-42af-9555-c3d9a38c6902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne.externals.pymatreader import read_mat\n",
    "\n",
    "from read import read_features\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246d55dc-8e49-4f2d-92fa-d580b45e32db",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    'leve': 0,\n",
    "    'moderada': 1,\n",
    "    'severa': 2\n",
    "}\n",
    "\n",
    "def parse_y(y, lim_leve=0.075, lim_moderada=0.15):\n",
    "    def classify(val):\n",
    "        if (val <= lim_leve):\n",
    "            return labels['leve']\n",
    "        if (val <= lim_moderada):\n",
    "            return labels['moderada']\n",
    "        return labels['severa']\n",
    "    \n",
    "    len_y = len(y)\n",
    "    classified = np.zeros(len_y, dtype=int)\n",
    "    \n",
    "    for i in range(len_y):\n",
    "        classified[i] = classify(y[i])\n",
    "        \n",
    "    return classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b3c7fc-b100-48c9-87f9-234676691435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Las que mejores graficas tienen\n",
    "# features_files = ['4_20151105_noon.mat', '4_20151107_noon.mat', '5_20141108_noon.mat','12_20150928_noon.mat','14_20151014_night.mat', '18_20150926_noon.mat', '21_20151016_noon.mat']\n",
    "\n",
    "# features_files = ['4_20151105_noon.mat', '5_20141108_noon.mat', '21_20151016_noon.mat']\n",
    "\n",
    "features_files = ['1_20151124_noon_2.csv', '2_20151106_noon.csv', '3_20151024_noon.csv','4_20151105_noon.csv', '4_20151107_noon.csv',\n",
    "            '5_20141108_noon.csv', '5_20151012_night.csv', '6_20151121_noon.csv','7_20151015_night.csv', '8_20151022_noon.csv', \n",
    "            '9_20151017_night.csv', '10_20151125_noon.csv', '11_20151024_night.csv', '12_20150928_noon.csv', '13_20150929_noon.csv',\n",
    "            '14_20151014_night.csv','15_20151126_night.csv', '16_20151128_night.csv', '17_20150925_noon.csv', '18_20150926_noon.csv',\n",
    "            '19_20151114_noon.csv', '20_20151129_night.csv', '21_20151016_noon.csv']\n",
    "\n",
    "# features_files = ['21_20151016_noon.csv']\n",
    "\n",
    "X_all = {} # psd\n",
    "X_all_eog = {} # psd + eog\n",
    "y_all = {} # datos perclos raw\n",
    "y_all_limits = {} # thresholds perclos para cada experimento\n",
    "y_all_class = {} # datos parseados a su clase\n",
    "\n",
    "for experiment in features_files:\n",
    "    \n",
    "    ''' EOG parpadeos por epoch'''\n",
    "    mat_data = read_mat(f'./SEED-VIG/Raw_Data/{experiment[:-4]}.mat')\n",
    "    \n",
    "    sfreq = mat_data['EOG']['eog_config']['current_sample_rate']\n",
    "    samples = mat_data['EOG']['eog_h']*1e-6 \n",
    "    samples = np.vstack((samples, mat_data['EOG']['eog_v']*1e-6))\n",
    "\n",
    "    ch_names = ['EOG_H', 'EOG_V']\n",
    "    ch_types = [\"eog\"]*len(ch_names)\n",
    "\n",
    "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "\n",
    "    info.set_montage('standard_1020')\n",
    "    \n",
    "    raw = mne.io.RawArray(samples, info, verbose=False)\n",
    "    \n",
    "    # Busqueda del treshold para el parpadeo\n",
    "    # En los 5 primeros segundos del experimento, buscamos el percentil 2.5 y calculamos su valor absoluto como threshold para detectar parpadeos\n",
    "    threshold = abs(np.percentile(raw.get_data()[1][:5*1000], 2.5))\n",
    "    \n",
    "    blinks = mne.preprocessing.find_eog_events(raw, filter_length='10s', thresh=threshold, verbose=False)\n",
    "    blinks = blinks.T[0]\n",
    "    \n",
    "    n_samples = 885\n",
    "    dur_sample = 8 # segs\n",
    "    len_sample = 8*125\n",
    "    \n",
    "    blinks_per_sample = []\n",
    "    for i in range(n_samples):\n",
    "        blinks_per_sample.append([])\n",
    "        \n",
    "    for val in blinks:\n",
    "        blinks_per_sample[val//len_sample].append(val)\n",
    "    \n",
    "    n_blinks_per_sample = [0]*n_samples\n",
    "        \n",
    "    for i in range(885):\n",
    "        n_blinks_per_sample[i] = len(blinks_per_sample[i])\n",
    "        \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    n_blinks_per_sample = np.array(n_blinks_per_sample)\n",
    "    n_blinks_per_sample = scaler.fit_transform(n_blinks_per_sample.reshape(-1,1))\n",
    "    \n",
    "    \n",
    "    ''' PSD '''\n",
    "    mat_data = read_mat(f'./SEED-VIG/EEG_Feature_5Bands/{experiment[:-4]}.mat')\n",
    "    perclos_data = read_mat(f'./SEED-VIG/perclos_labels/{experiment[:-4]}.mat')\n",
    "    y = np.array(perclos_data['perclos'])\n",
    "\n",
    "    n_channels = 17\n",
    "    psd_data = mat_data['psd_movingAve']\n",
    "    perclos = []\n",
    "    psd_delta = []\n",
    "    psd_theta = []\n",
    "    psd_alpha = []\n",
    "    psd_beta = []\n",
    "    psd_gamma = []\n",
    "    start = 0\n",
    "    end = 885\n",
    "    for t in range(start, end):\n",
    "        vals= np.zeros(5)\n",
    "\n",
    "        for i in range(n_channels):\n",
    "            vals[0] += psd_data[i][t][0]\n",
    "            vals[1] += psd_data[i][t][1]\n",
    "            vals[2] += psd_data[i][t][2]\n",
    "            vals[3] += psd_data[i][t][3]\n",
    "            vals[4] += psd_data[i][t][4]\n",
    "        vals /= 17\n",
    "\n",
    "        perclos.append(y[t])\n",
    "        psd_delta.append(vals[0])\n",
    "        psd_theta.append(vals[1])\n",
    "        psd_alpha.append(vals[2])\n",
    "        psd_beta.append(vals[3])\n",
    "        psd_gamma.append(vals[4])\n",
    "\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    psd_delta = np.array(psd_delta)\n",
    "    psd_delta = scaler.fit_transform(psd_delta.reshape(-1,1))\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    psd_theta = np.array(psd_theta)\n",
    "    psd_theta = scaler.fit_transform(psd_theta.reshape(-1,1))\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    psd_alpha = np.array(psd_alpha)\n",
    "    psd_alpha = scaler.fit_transform(psd_alpha.reshape(-1,1))\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    psd_beta = np.array(psd_beta)\n",
    "    psd_beta = scaler.fit_transform(psd_beta.reshape(-1,1))\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    psd_gamma = np.array(psd_gamma)\n",
    "    psd_gamma = scaler.fit_transform(psd_gamma.reshape(-1,1))\n",
    "\n",
    "    X = psd_delta\n",
    "    X = np.hstack((X, psd_theta))\n",
    "    X = np.hstack((X, psd_alpha))\n",
    "    X = np.hstack((X, psd_beta))\n",
    "    ''' DESCOMENTAR PARA USAR PSD DE GAMMA '''\n",
    "    X = np.hstack((X, psd_gamma))\n",
    "    \n",
    "    X_all[f'{experiment[:-4]}'] = X # guardamos los psd\n",
    "    \n",
    "    X = np.hstack((X, n_blinks_per_sample))\n",
    "    \n",
    "    X_all_eog[f'{experiment[:-4]}'] = X # guardamos psd + eog\n",
    "    \n",
    "    ''' LABELS '''\n",
    "    y_all[f'{experiment[:-4]}'] = y # guardamos perclos raw\n",
    "    \n",
    "    range_values = (np.max(y)-np.min(y))/100\n",
    "    lim_leve = np.min(y)+range_values*12.5\n",
    "    lim_moderada = np.min(y)+range_values*30\n",
    "    y_all_limits[f'{experiment[:-4]}'] = [lim_leve, lim_moderada]\n",
    "    \n",
    "    y_all_class[f'{experiment[:-4]}'] = parse_y(y, lim_leve, lim_moderada) # guardamos ya clasificada\n",
    "    \n",
    "print(f'Generados los diccionarios X_all e y_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdee812e-c7b2-482e-97a1-38a02a22325c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(X_all_eog['1_20151124_noon_2'].shape)\n",
    "\n",
    "for key in X_all:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787e9cf9-a5e6-4b95-ae6b-70db99a77c50",
   "metadata": {},
   "source": [
    "# Busqueda de hyperparametros y muestra de los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed56c86f-8fc0-46aa-813e-09978d533f97",
   "metadata": {},
   "source": [
    "## Funciones para la busqueda y el plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c35d8ff-769c-4e63-9d42-a845282cc76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "from scipy.stats import uniform, randint, loguniform, gamma\n",
    "\n",
    "def find_and_test_best_model_clust(X, y, model, space, cv=10, n_iter=100, scoring=None):\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    search = RandomizedSearchCV(model, space, n_iter=n_iter, scoring=scoring, n_jobs=-1, cv=cv, random_state=42)\n",
    "    result = search.fit(X, y)\n",
    "    \n",
    "    print(f\"Best Model:\")\n",
    "    print(f\"\\tScore: {result.best_score_:.4f}\")\n",
    "    print(f\"\\tHyperparameters: {result.best_params_}\")\n",
    "    \n",
    "    print('\\nCluestering evaluation:')\n",
    "    best_model = result.best_estimator_\n",
    "    final_predictions = best_model.predict(X)\n",
    "    \n",
    "    # The score is bounded between -1 for incorrect clustering and +1 for highly dense clustering. Scores around zero indicate overlapping clusters.\n",
    "    silhouette = silhouette_score(X, final_predictions)\n",
    "    print(f\"\\tSilhouette Coefficient: {silhouette:.4f}\")\n",
    "    \n",
    "    # The score is higher when clusters are dense and well separated, which relates to a standard concept of a cluster.\n",
    "    calinski = calinski_harabasz_score(X, final_predictions)\n",
    "    print(f\"\\tCalinski-Harabasz Index: {calinski:.4f}\")\n",
    "    \n",
    "    # This index signifies the average 'similarity' between clusters, where the similarity is a measure that compares the distance between clusters with the size of the clusters themselves.\n",
    "    # Zero is the lowest possible score. Values closer to zero indicate a better partition.\n",
    "    davies = davies_bouldin_score(X, final_predictions)\n",
    "    print(f\"\\tDavies Bouldin Index: {davies:.4f}\")\n",
    "    \n",
    "    return best_model, silhouette, calinski, davies\n",
    "\n",
    "def plot_results_clust(X, y, model, lim_leve_moderada, lim_moderada_severa):\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.axhline(y=lim_leve_moderada, color='orange', linestyle='-', zorder=0, linewidth=3)\n",
    "    plt.axhline(y=lim_moderada_severa, color='red', linestyle='-', zorder=0, linewidth=3)\n",
    "    plt.plot(y, c='k', alpha=0.6)\n",
    "    colors = model.predict(X)\n",
    "    plt.scatter(range(len(y)), y, c=colors)\n",
    "    #plt.legend(bbox_to_anchor=(1, 1), loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b22f43-b568-459e-a8f5-f5aa6bed663a",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e86c0-5ee6-44ef-a935-d6e0b26ad1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f3bb2-5682-488d-b7f3-4aeb2e9dfb6e",
   "metadata": {},
   "source": [
    "### EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d84fac4-acde-4386-a914-74665f676996",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'silhouette': [],\n",
    "    'calinski': [],\n",
    "    'davies': []\n",
    "}\n",
    "\n",
    "for key in X_all:\n",
    "    X, y = read_features(f'./features/{key}.csv')\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_minmax = scaler.fit_transform(X)\n",
    "    \n",
    "    print(f\"Experiment: {key}\")\n",
    "    model = KMeans(random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['n_clusters'] = [2, 3, 4]\n",
    "    space['init'] = ['k-means++', 'random']\n",
    "    space['n_init'] = randint(5, 20)\n",
    "    space['max_iter'] = randint(200, 400)\n",
    "    space['tol'] = [1e-3, 5e-3, 1e-4, 5e-4, 1e-5, 5e-5]\n",
    "    space['algorithm'] = ['auto', 'full', 'elkan']\n",
    "\n",
    "    best_model, silhouette, calinski, davies = find_and_test_best_model_clust(X_minmax, y_all[key], model, space, cv=10, n_iter=20)\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['silhouette'].append(silhouette)\n",
    "    csv_dict['calinski'].append(calinski)\n",
    "    csv_dict['davies'].append(davies)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_clust(X_minmax, y_all[key], best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_clust/KMeans-EEG.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381d4b1f-7ff7-43cf-a1eb-f951badf7cb8",
   "metadata": {},
   "source": [
    "### PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffeafcb-2e63-46a8-a9fc-14a657eb0e7a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'silhouette': [],\n",
    "    'calinski': [],\n",
    "    'davies': []\n",
    "}\n",
    "\n",
    "for key in X_all:\n",
    "    print(f\"Experiment: {key}\")\n",
    "    model = KMeans(random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['n_clusters'] = [2, 3, 4]\n",
    "    space['init'] = ['k-means++', 'random']\n",
    "    space['n_init'] = randint(5, 20)\n",
    "    space['max_iter'] = randint(200, 400)\n",
    "    space['tol'] = [1e-3, 5e-3, 1e-4, 5e-4, 1e-5, 5e-5]\n",
    "    space['algorithm'] = ['auto', 'full', 'elkan']\n",
    "\n",
    "    best_model, silhouette, calinski, davies = find_and_test_best_model_clust(X_all[key], y_all[key], model, space, cv=10, n_iter=20)\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['silhouette'].append(silhouette)\n",
    "    csv_dict['calinski'].append(calinski)\n",
    "    csv_dict['davies'].append(davies)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_clust(X_all[key], y_all[key], best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_clust/KMeans-PSD.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e912e9fb-d683-49c0-b4c3-f649cead7dd7",
   "metadata": {},
   "source": [
    "### PSD + EOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93a751f-c71f-4267-902f-664ede74cb5a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'silhouette': [],\n",
    "    'calinski': [],\n",
    "    'davies': []\n",
    "}\n",
    "\n",
    "for key in X_all:\n",
    "    print(f\"Experiment: {key}\")\n",
    "    model = KMeans(random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['n_clusters'] = [2, 3, 4]\n",
    "    space['init'] = ['k-means++', 'random']\n",
    "    space['n_init'] = randint(5, 20)\n",
    "    space['max_iter'] = randint(200, 400)\n",
    "    space['tol'] = [1e-3, 5e-3, 1e-4, 5e-4, 1e-5, 5e-5]\n",
    "    space['algorithm'] = ['auto', 'full', 'elkan']\n",
    "\n",
    "    best_model, silhouette, calinski, davies = find_and_test_best_model_clust(X_all_eog[key], y_all[key], model, space, cv=10, n_iter=20)\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['silhouette'].append(silhouette)\n",
    "    csv_dict['calinski'].append(calinski)\n",
    "    csv_dict['davies'].append(davies)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_clust(X_all_eog[key], y_all[key], best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_clust/KMeans-PSD+EOG.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9738b5c-7ec0-4ed0-b953-83bce8b3f25d",
   "metadata": {},
   "source": [
    "### Resto de cosas de K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0510e54-ed15-470f-83b9-3457e966bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa3703d-bbad-4084-b900-273f59de2b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kmeans_simple_plot(X, y, n_plots=3):\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=n_plots ,figsize=(20,4))\n",
    "\n",
    "    for k in range(2, 2+n_plots):\n",
    "        ax[k-2].title.set_text(f\"Clusters when k={k}\")\n",
    "\n",
    "        kmeans = KMeans(n_clusters=k)\n",
    "        y_pred = kmeans.fit_predict(X)\n",
    "\n",
    "        ax[k-2].scatter(X.T[0], X.T[1], c=y_pred)\n",
    "        centroids = kmeans.cluster_centers_\n",
    "        ax[k-2].scatter(centroids[:, 0], centroids[:, 1], s=100, c='red')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8394f112-6b35-4b94-afde-679fcf5afc44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kmeans_complex_plot(X, y, n_plots=3):\n",
    "    # Grafica compleja\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=n_plots, ncols=2 ,figsize=(20,15))\n",
    "    fig. tight_layout(pad=5)\n",
    "\n",
    "    for k in range(2, 2+n_plots):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        y_pred = kmeans.fit_predict(X)\n",
    "\n",
    "        ### Silhouette Diagram ###\n",
    "\n",
    "        ax[k-2][0].set_xlim([-0.1, 1])\n",
    "        ax[k-2][0].set_ylim([0, len(X) + (k + 1) * 10])\n",
    "\n",
    "        silhouette_avg = silhouette_score(X, y_pred)\n",
    "\n",
    "        sample_silhouette_values = silhouette_samples(X, y_pred)\n",
    "\n",
    "        y_lower = 10\n",
    "        for i in range(k):\n",
    "            # Aggregate the silhouette scores for samples belonging to\n",
    "            # cluster i, and sort them\n",
    "            ith_cluster_silhouette_values = \\\n",
    "                sample_silhouette_values[y_pred == i]\n",
    "\n",
    "            ith_cluster_silhouette_values.sort()\n",
    "\n",
    "            size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "            y_upper = y_lower + size_cluster_i\n",
    "\n",
    "            color = cm.nipy_spectral(float(i) / k)\n",
    "            ax[k-2][0].fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                              0, ith_cluster_silhouette_values,\n",
    "                              facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "            # Label the silhouette plots with their cluster numbers at the middle\n",
    "            ax[k-2][0].text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "            # Compute the new y_lower for next plot\n",
    "            y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "        ax[k-2][0].axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "        ax[k-2][0].set_title(f\"The silhouette diagram for n_clusters = {k}. Avg = {silhouette_avg:.3f}\")\n",
    "        ax[k-2][0].set_xlabel(\"The silhouette coefficient values\")\n",
    "        ax[k-2][0].set_ylabel(\"Cluster label\")\n",
    "\n",
    "        ax[k-2][0].set_yticks([])  # Clear the yaxis labels / ticks\n",
    "        ax[k-2][0].set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "        ### Clusters Visualization ###\n",
    "        ax[k-2][1].set_title(f\"Clusters visualization for n_clusters = {k}\")\n",
    "        ax[k-2][1].scatter(X.T[0], X.T[1], marker='.', s=50, lw=0, alpha=1,c=y_pred, edgecolor='k')\n",
    "        centroids = kmeans.cluster_centers_\n",
    "        ax[k-2][1].scatter(centroids[:, 0], centroids[:, 1], marker='o', c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "        for i, c in enumerate(centroids):\n",
    "                ax[k-2][1].scatter(c[0], c[1], marker='$%d$' % i, alpha=1, s=50, edgecolor='k')\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data with n_clusters from %d to %d\" % (2, n_plots+1)), fontweight='bold')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32939bf6-2119-4bf6-b840-28873d5d2679",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kmeans_predictions_plot(X, y, k=3):\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    predictions = kmeans.fit_predict(X)\n",
    "\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.plot(y, color='gray')\n",
    "    plt.scatter(range(len(predictions)), y, c=predictions)\n",
    "    plt.title('Coloreado del valor PERCLOS y el cluster asociado')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('% PERCLOS')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9327eeb8-0867-4d6a-94eb-3ff63a8ac88d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "k_values = list(range(2, 5+1))\n",
    "silhouette_scores = []\n",
    "\n",
    "key = '11_20151024_night'\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    \n",
    "    kmeans.fit_predict(X_all[key])\n",
    "    silhouette_scores.append(silhouette_score(X_all[key], kmeans.labels_))\n",
    "    \n",
    "plt.plot(k_values, silhouette_scores, '-o', label='normal')\n",
    "plt.xticks(range(2,6))\n",
    "plt.ylim([0, 1])\n",
    "plt.title('Comparativa entre el k y el valor de Silhouette')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('silhouette score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dae2b7-30ac-439f-b977-1ce039c8dcfe",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kmeans_simple_plot(X_all[key], y_all[key], 4)\n",
    "kmeans_complex_plot(X_all[key], y_all[key], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a7bcdf-43b2-4916-a0ea-60135d72cb8d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kmeans_predictions_plot(X_all[key], y_all[key], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f7e6ad-f87d-439a-a2e0-89fa30b2b6b4",
   "metadata": {},
   "source": [
    "## GM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d28bd9-6845-4d88-b80f-8cd07eb71adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360b1a6d-898f-4f26-8b08-dcc879848090",
   "metadata": {},
   "source": [
    "### EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b8742d-e0ef-4cdc-b725-1a406f82883d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "key = '21_20151016_noon'\n",
    "\n",
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'silhouette': [],\n",
    "    'calinski': [],\n",
    "    'davies': []\n",
    "}\n",
    "\n",
    "for key in X_all:\n",
    "    X, y = read_features(f'./features/{key}.csv')\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_minmax = scaler.fit_transform(X)\n",
    "    \n",
    "    \n",
    "    print(f\"Experiment: {key}\")\n",
    "    model = GaussianMixture(max_iter=200, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['n_components'] = randint(2, 4)\n",
    "    space['covariance_type'] = ['full', 'tied', 'diag', 'spherical']\n",
    "    space['tol'] = [1e-3, 5e-3, 1e-4, 5e-4, 1e-5, 5e-5]\n",
    "    space['reg_covar'] = [1e-7, 5e-7, 1e-6, 5e-6, 1e-5, 5e-5]\n",
    "    space['n_init'] = randint(1, 5)\n",
    "    space['init_params'] = ['kmeans', 'random']\n",
    "    space['warm_start'] = [True, False]\n",
    "\n",
    "    best_model, silhouette, calinski, davies = find_and_test_best_model_clust(X_minmax, y_all[key], model, space, cv=10, n_iter=30)\n",
    "    \n",
    "    print(f'Ha convergido? {best_model.converged_}, n_its: {best_model.n_iter_}')\n",
    "    print(np.round(best_model.weights_,2))\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['silhouette'].append(silhouette)\n",
    "    csv_dict['calinski'].append(calinski)\n",
    "    csv_dict['davies'].append(davies)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_clust(X_minmax, y_all[key], best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_clust/GM-EEG.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e24e1b-9505-46bd-be98-eae840a70d21",
   "metadata": {},
   "source": [
    "### PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2f3b91-9266-42e8-8923-33303d1d9129",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "key = '21_20151016_noon'\n",
    "\n",
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'silhouette': [],\n",
    "    'calinski': [],\n",
    "    'davies': []\n",
    "}\n",
    "\n",
    "for key in X_all:\n",
    "    print(f\"Experiment: {key}\")\n",
    "    model = GaussianMixture(max_iter=200, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['n_components'] = randint(2, 4)\n",
    "    space['covariance_type'] = ['full', 'tied', 'diag', 'spherical']\n",
    "    space['tol'] = [1e-3, 5e-3, 1e-4, 5e-4, 1e-5, 5e-5]\n",
    "    space['reg_covar'] = [1e-7, 5e-7, 1e-6, 5e-6, 1e-5, 5e-5]\n",
    "    space['n_init'] = randint(1, 5)\n",
    "    space['init_params'] = ['kmeans', 'random']\n",
    "    space['warm_start'] = [True, False]\n",
    "\n",
    "    best_model, silhouette, calinski, davies = find_and_test_best_model_clust(X_all[key], y_all[key], model, space, cv=10, n_iter=30)\n",
    "    \n",
    "    print(f'Ha convergido? {best_model.converged_}, n_its: {best_model.n_iter_}')\n",
    "    print(np.round(best_model.weights_,2))\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['silhouette'].append(silhouette)\n",
    "    csv_dict['calinski'].append(calinski)\n",
    "    csv_dict['davies'].append(davies)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_clust(X_all[key], y_all[key], best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_clust/GM-PSD.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0c81ef-6a2f-463c-8362-461902b5a31d",
   "metadata": {},
   "source": [
    "### PSD + EOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bedf7a-1206-4204-b147-a6a3edbefe32",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "key = '21_20151016_noon'\n",
    "\n",
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'silhouette': [],\n",
    "    'calinski': [],\n",
    "    'davies': []\n",
    "}\n",
    "\n",
    "for key in X_all:\n",
    "    print(f\"Experiment: {key}\")\n",
    "    model = GaussianMixture(max_iter=200, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['n_components'] = randint(2, 4)\n",
    "    space['covariance_type'] = ['full', 'tied', 'diag', 'spherical']\n",
    "    space['tol'] = [1e-3, 5e-3, 1e-4, 5e-4, 1e-5, 5e-5]\n",
    "    space['reg_covar'] = [1e-7, 5e-7, 1e-6, 5e-6, 1e-5, 5e-5]\n",
    "    space['n_init'] = randint(1, 5)\n",
    "    space['init_params'] = ['kmeans', 'random']\n",
    "    space['warm_start'] = [True, False]\n",
    "\n",
    "    best_model, silhouette, calinski, davies = find_and_test_best_model_clust(X_all_eog[key], y_all[key], model, space, cv=10, n_iter=30)\n",
    "    \n",
    "    print(f'Ha convergido? {best_model.converged_}, n_its: {best_model.n_iter_}')\n",
    "    print(np.round(best_model.weights_,2))\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['silhouette'].append(silhouette)\n",
    "    csv_dict['calinski'].append(calinski)\n",
    "    csv_dict['davies'].append(davies)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_clust(X_all_eog[key], y_all[key], best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_clust/GM-PSD+EOG.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b7fec0-5d20-4680-85e5-e3ca91097553",
   "metadata": {},
   "source": [
    "### Resto de cosas de GM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984108a1-3317-44fb-845a-aee89deacaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "def gm_predictions_plot(X, y, n=3):\n",
    "    gm = GaussianMixture(n_components=n, n_init=50)\n",
    "    gm.fit(X)\n",
    "    predictions = gm.predict(X)\n",
    "\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.plot(y, color='gray')\n",
    "    plt.scatter(range(len(predictions)), y, c=predictions)\n",
    "    plt.title('GMM - Coloreado del valor PERCLOS y el cluster asociado')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('% PERCLOS')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ce9867-0aa8-47a6-a8ae-09c496e9899a",
   "metadata": {},
   "source": [
    "# BGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f45be1-caca-4c51-81cd-b2676c01e9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import BayesianGaussianMixture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65919470-9f64-4925-98c1-bed860853efa",
   "metadata": {},
   "source": [
    "### EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac99007a-3828-4055-9bcc-34f47f60b57b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "key = '21_20151016_noon'\n",
    "\n",
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'silhouette': [],\n",
    "    'calinski': [],\n",
    "    'davies': []\n",
    "}\n",
    "\n",
    "for key in X_all:\n",
    "    X, y = read_features(f'./features/{key}.csv')\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_minmax = scaler.fit_transform(X)\n",
    "    \n",
    "    print(f\"Experiment: {key}\")\n",
    "    model = BayesianGaussianMixture(max_iter=200, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['n_components'] = randint(2, 4)\n",
    "    space['covariance_type'] = ['full', 'tied', 'diag', 'spherical']\n",
    "    space['tol'] = [1e-3, 5e-3, 1e-4, 5e-4, 1e-5, 5e-5]\n",
    "    space['reg_covar'] = [1e-7, 5e-7, 1e-6, 5e-6, 1e-5, 5e-5]\n",
    "    space['n_init'] = randint(1, 5)\n",
    "    space['init_params'] = ['kmeans', 'random']\n",
    "    space['weight_concentration_prior_type'] = ['dirichlet_process', 'dirichlet_distribution']\n",
    "    space['warm_start'] = [True, False]\n",
    "\n",
    "    best_model, silhouette, calinski, davies = find_and_test_best_model_clust(X_minmax, y_all[key], model, space, cv=10, n_iter=20)\n",
    "    \n",
    "    print(f'Ha convergido? {best_model.converged_}, n_its: {best_model.n_iter_}')\n",
    "    print(np.round(best_model.weights_,2))\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['silhouette'].append(silhouette)\n",
    "    csv_dict['calinski'].append(calinski)\n",
    "    csv_dict['davies'].append(davies)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_clust(X_minmax, y_all[key], best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_clust/BGM-EEG.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a0ff81-4597-431d-ba77-ffa1dccb52bb",
   "metadata": {},
   "source": [
    "### PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3a87a9-61c3-4383-a6cd-08ab469c043b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "key = '21_20151016_noon'\n",
    "\n",
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'silhouette': [],\n",
    "    'calinski': [],\n",
    "    'davies': []\n",
    "}\n",
    "\n",
    "for key in X_all:\n",
    "    print(f\"Experiment: {key}\")\n",
    "    model = BayesianGaussianMixture(max_iter=200, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['n_components'] = randint(2, 4)\n",
    "    space['covariance_type'] = ['full', 'tied', 'diag', 'spherical']\n",
    "    space['tol'] = [1e-3, 5e-3, 1e-4, 5e-4, 1e-5, 5e-5]\n",
    "    space['reg_covar'] = [1e-7, 5e-7, 1e-6, 5e-6, 1e-5, 5e-5]\n",
    "    space['n_init'] = randint(1, 5)\n",
    "    space['init_params'] = ['kmeans', 'random']\n",
    "    space['weight_concentration_prior_type'] = ['dirichlet_process', 'dirichlet_distribution']\n",
    "    space['warm_start'] = [True, False]\n",
    "\n",
    "    best_model, silhouette, calinski, davies = find_and_test_best_model_clust(X_all[key], y_all[key], model, space, cv=10, n_iter=20)\n",
    "    \n",
    "    print(f'Ha convergido? {best_model.converged_}, n_its: {best_model.n_iter_}')\n",
    "    print(np.round(best_model.weights_,2))\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['silhouette'].append(silhouette)\n",
    "    csv_dict['calinski'].append(calinski)\n",
    "    csv_dict['davies'].append(davies)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_clust(X_all[key], y_all[key], best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_clust/BGM-PSD.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e725bce1-c871-4bf7-ac45-73a7b241252d",
   "metadata": {},
   "source": [
    "### PSD + EOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c58e0a-7a20-411d-a410-f825e2bae6fd",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "key = '21_20151016_noon'\n",
    "\n",
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'silhouette': [],\n",
    "    'calinski': [],\n",
    "    'davies': []\n",
    "}\n",
    "\n",
    "for key in X_all:\n",
    "    print(f\"Experiment: {key}\")\n",
    "    model = BayesianGaussianMixture(max_iter=200, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['n_components'] = randint(2, 4)\n",
    "    space['covariance_type'] = ['full', 'tied', 'diag', 'spherical']\n",
    "    space['tol'] = [1e-3, 5e-3, 1e-4, 5e-4, 1e-5, 5e-5]\n",
    "    space['reg_covar'] = [1e-7, 5e-7, 1e-6, 5e-6, 1e-5, 5e-5]\n",
    "    space['n_init'] = randint(1, 5)\n",
    "    space['init_params'] = ['kmeans', 'random']\n",
    "    space['weight_concentration_prior_type'] = ['dirichlet_process', 'dirichlet_distribution']\n",
    "    space['warm_start'] = [True, False]\n",
    "\n",
    "    best_model, silhouette, calinski, davies = find_and_test_best_model_clust(X_all_eog[key], y_all[key], model, space, cv=10, n_iter=20)\n",
    "    \n",
    "    print(f'Ha convergido? {best_model.converged_}, n_its: {best_model.n_iter_}')\n",
    "    print(np.round(best_model.weights_,2))\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['silhouette'].append(silhouette)\n",
    "    csv_dict['calinski'].append(calinski)\n",
    "    csv_dict['davies'].append(davies)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_clust(X_all_eog[key], y_all[key], best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_clust/BGM-PSD+EOG.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7514408b-c287-42cf-883e-f4620c4e20dc",
   "metadata": {},
   "source": [
    "### Resto de cosas de Bayesian Gaussian Mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ab3003-7e02-401c-a52a-6bd1469ef6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "def bgm_predictions_plot(X, y):\n",
    "    bgm = BayesianGaussianMixture(n_components=6, n_init=20, random_state=42)\n",
    "    bgm.fit(X)\n",
    "\n",
    "    print(f'Ha convergido? {bgm.converged_}, n_its: {bgm.n_iter_}')\n",
    "    print(np.round(bgm.weights_,2))\n",
    "\n",
    "    predictions = bgm.predict(X)\n",
    "\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.plot(y, color='gray')\n",
    "    plt.scatter(range(len(predictions)), y, c=predictions)\n",
    "    plt.title('BGM - Coloreado del valor PERCLOS y el cluster asociado')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('% PERCLOS')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93f66eb-e8aa-4df2-ba1b-1fff8a75a6d0",
   "metadata": {},
   "source": [
    "# Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b0659e-9774-4df7-b2af-c5f098afa1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59822363-6217-4ae3-bc84-c002d4bedf50",
   "metadata": {},
   "source": [
    "### EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162a0fe6-deec-4897-930c-e6542f900f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "key = '21_20151016_noon'\n",
    "\n",
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'silhouette': [],\n",
    "    'calinski': [],\n",
    "    'davies': []\n",
    "}\n",
    "\n",
    "for key in X_all:\n",
    "    X, y = read_features(f'./features/{key}.csv')\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_minmax = scaler.fit_transform(X)\n",
    "    \n",
    "    print(f\"Experiment: {key}\")\n",
    "    model = AffinityPropagation(max_iter=1000, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['damping'] = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    space['convergence_iter'] = randint(8, 15)\n",
    "    space['preference'] = range(-1, -10, -1)\n",
    "\n",
    "    best_model, silhouette, calinski, davies = find_and_test_best_model_clust(X_minmax, y_all[key], model, space, cv=5, n_iter=10, scoring='homogeneity_score')\n",
    "    \n",
    "    cluster_centers_indices = best_model.cluster_centers_indices_\n",
    "    n_clusters_ = len(cluster_centers_indices)\n",
    "    print(f'Numero de Clusters: {n_clusters_}')\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['silhouette'].append(silhouette)\n",
    "    csv_dict['calinski'].append(calinski)\n",
    "    csv_dict['davies'].append(davies)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_clust(X_minmax, y_all[key], best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_clust/AffProp-EEG.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ff5418-095f-482d-b607-8ad7b9836436",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = '21_20151016_noon'\n",
    "\n",
    "\n",
    "print(f\"Experiment: {key}\")\n",
    "model = AffinityPropagation(max_iter=1000, random_state=42)\n",
    "\n",
    "space = dict()\n",
    "space['damping'] = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "space['convergence_iter'] = randint(8, 15)\n",
    "space['preference'] = range(-1, -10, -1)\n",
    "\n",
    "best_model, silhouette, calinski, davies = find_and_test_best_model_clust(X_all[key], y_all[key], model, space, cv=5, n_iter=10, scoring='homogeneity_score')\n",
    "\n",
    "cluster_centers_indices = best_model.cluster_centers_indices_\n",
    "n_clusters_ = len(cluster_centers_indices)\n",
    "print(f'Numero de Clusters: {n_clusters_}')\n",
    "\n",
    "lim_leve_moderada, lim_moderada_severa = y_all_limits[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8e64a9-c2cc-40fa-8dfe-08a32a6d3e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.axhline(y=lim_leve_moderada, color='orange', linestyle='-', zorder=0, linewidth=3)\n",
    "plt.axhline(y=lim_moderada_severa, color='red', linestyle='-', zorder=0, linewidth=3)\n",
    "plt.plot(y_all[key], c='k', alpha=0.6)\n",
    "colors = best_model.predict(X_all[key])\n",
    "plt.scatter(range(len(y_all[key])), y_all[key], c=colors)\n",
    "size_label = 26; plt.xlabel('Epoch', fontweight ='bold', labelpad = 10,fontsize = size_label); plt.ylabel('PERCLOS', fontweight ='bold', labelpad = 10,fontsize = size_label);\n",
    "size_ticks = 24; plt.xticks(fontsize=size_ticks); plt.yticks(fontsize=size_ticks);\n",
    "plt.savefig(\"E:/UNIVERSIDAD/TFG/TRABAJO/Images-Test/NOMBRE2.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdb040b-54aa-41cb-aeb6-c6778cb8914a",
   "metadata": {},
   "source": [
    "### PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a3393a-3120-4f89-9403-26b2a02f06cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "key = '21_20151016_noon'\n",
    "\n",
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'silhouette': [],\n",
    "    'calinski': [],\n",
    "    'davies': []\n",
    "}\n",
    "\n",
    "for key in X_all:\n",
    "    print(f\"Experiment: {key}\")\n",
    "    model = AffinityPropagation(max_iter=1000, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['damping'] = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    space['convergence_iter'] = randint(8, 15)\n",
    "    space['preference'] = range(-1, -10, -1)\n",
    "\n",
    "    best_model, silhouette, calinski, davies = find_and_test_best_model_clust(X_all[key], y_all[key], model, space, cv=5, n_iter=10, scoring='homogeneity_score')\n",
    "    \n",
    "    cluster_centers_indices = best_model.cluster_centers_indices_\n",
    "    n_clusters_ = len(cluster_centers_indices)\n",
    "    print(f'Numero de Clusters: {n_clusters_}')\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['silhouette'].append(silhouette)\n",
    "    csv_dict['calinski'].append(calinski)\n",
    "    csv_dict['davies'].append(davies)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_clust(X_all[key], y_all[key], best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_clust/AffProp-PSD.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cd04cd-8966-4c9e-967d-00d0581ec52c",
   "metadata": {},
   "source": [
    "### PSD + EOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8caf2c-2feb-4ee2-8115-39ae2c38d4be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "key = '21_20151016_noon'\n",
    "\n",
    "csv_dict = {\n",
    "    'sujeto': [],\n",
    "    'silhouette': [],\n",
    "    'calinski': [],\n",
    "    'davies': []\n",
    "}\n",
    "\n",
    "for key in X_all:\n",
    "    print(f\"Experiment: {key}\")\n",
    "    model = AffinityPropagation(max_iter=1000, random_state=42)\n",
    "\n",
    "    space = dict()\n",
    "    space['damping'] = [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    space['convergence_iter'] = randint(8, 15)\n",
    "    space['preference'] = range(-1, -10, -1)\n",
    "\n",
    "    best_model, silhouette, calinski, davies = find_and_test_best_model_clust(X_all_eog[key], y_all[key], model, space, cv=5, n_iter=10, scoring='homogeneity_score')\n",
    "    \n",
    "    cluster_centers_indices = best_model.cluster_centers_indices_\n",
    "    n_clusters_ = len(cluster_centers_indices)\n",
    "    print(f'Numero de Clusters: {n_clusters_}')\n",
    "    \n",
    "    csv_dict['sujeto'].append(key)\n",
    "    csv_dict['silhouette'].append(silhouette)\n",
    "    csv_dict['calinski'].append(calinski)\n",
    "    csv_dict['davies'].append(davies)\n",
    "\n",
    "    lim_leve_moderada, lim_moderada_severa = y_all_limits[key]\n",
    "    plot_results_clust(X_all_eog[key], y_all[key], best_model, lim_leve_moderada, lim_moderada_severa)\n",
    "    \n",
    "df = pd.DataFrame(csv_dict)\n",
    "df.to_csv('./results_clust/AffProp-PSD+EOG.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8a1813-3b9b-4bb9-b1df-6794eebaf66b",
   "metadata": {},
   "source": [
    "### Resto de cosas de Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e1ee94-a472-4990-a00b-c6b4fc0cd044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn import metrics\n",
    "\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904e1558-55ce-4032-86f6-4515c694afbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_files = ['4_20151105_noon.mat', '4_20151107_noon.mat', '5_20141108_noon.mat','12_20150928_noon.mat','14_20151014_night.mat', '18_20150926_noon.mat', '21_20151016_noon.mat']\n",
    "key = '21_20151016_noon'\n",
    "\n",
    "af = AffinityPropagation(preference=-6, max_iter=3000, affinity='euclidean', random_state=42)\n",
    "\n",
    "af.fit(X_all[key])\n",
    "\n",
    "cluster_centers_indices = af.cluster_centers_indices_\n",
    "predictions = af.labels_\n",
    "n_clusters_ = len(cluster_centers_indices)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4866bcda-7937-4e77-bd6e-88c1913fb629",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = cycle('bgrcmykbgrcmykbgrcmykbgrcmyk')\n",
    "for k, col in zip(range(n_clusters_), colors):\n",
    "    class_members = predictions == k\n",
    "    cluster_center = X_all[key][cluster_centers_indices[k]]\n",
    "    plt.plot(X_all[key][class_members, 0], X_all[key][class_members, 1], col + '.')\n",
    "    plt.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col, markeredgecolor='k', markersize=14)\n",
    "    for x in X_all[key][class_members]:\n",
    "        plt.plot([cluster_center[0], x[0]], [cluster_center[1], x[1]], col)\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a762238d-1ca3-4331-a779-2ab81ad008e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(y_all[key], color='r', alpha=0.7)\n",
    "plt.scatter(range(len(predictions)), y_all[key], c=predictions)\n",
    "plt.title('AP - Coloreado del valor PERCLOS y el cluster asociado')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('% PERCLOS')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
